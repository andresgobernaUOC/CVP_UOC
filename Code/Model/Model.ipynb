{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe99b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e9a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Input Data Source\n",
    "input_file = os.path.join(f'D0_Source.csv')\n",
    "input_file='../SourceData/D0_Source.csv'\n",
    "D0_Source=pl.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d2b1a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Model Parameters\n",
    "periodGroup=12  #Number of periods in a rolling window\n",
    "userMin_periods_in_PG=3 #min number of observations in the subset to perform the regression analysis\n",
    "userMax_periods_in_PG=12 #max number of observations in the subset to perform the regression analysis\n",
    "scenarioNameBase=\"PG12\"  #User Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0e500f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Model Parameters Validation\n",
    "now = datetime.now()\n",
    "runtTimeVersion = now.strftime(\"%Y%m%d%H%M\")\n",
    "inputPeriodsN=D0_Source.select(\"periodID\").unique().shape[0]\n",
    "\n",
    "if(periodGroup>inputPeriodsN):\n",
    "    periodGroup=inputPeriodsN\n",
    "    \n",
    "if(userMin_periods_in_PG>periodGroup):\n",
    "    userMin_periods_in_PG=periodGroup\n",
    "\n",
    "if(userMin_periods_in_PG>userMax_periods_in_PG):\n",
    "    userMax_periods_in_PG=userMin_periods_in_PG\n",
    "\n",
    "if(userMax_periods_in_PG>periodGroup):\n",
    "    userMax_periods_in_PG=periodGroup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "49d2f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Version control process\n",
    "input_file = 'D0_VersionControl.csv'\n",
    "now = datetime.now()\n",
    "\n",
    "# Validation of File Exist, if not, generate.\n",
    "try:\n",
    "    \n",
    "    D0_VersionControl = pl.read_csv(input_file)\n",
    "    \n",
    "    D0_VersionControl = D0_VersionControl.with_columns(\n",
    "        pl.arange(1, D0_VersionControl.height + 1).alias('scenarioID')\n",
    "    )\n",
    "    \n",
    "    scenarioID_var = D0_VersionControl['scenarioID'].max()\n",
    "    scenarioID = scenarioID_var + 1\n",
    "except FileNotFoundError:\n",
    "    \n",
    "    D0_VersionControl = pl.DataFrame()\n",
    "    scenarioID = 1  \n",
    "\n",
    "\n",
    "scenarioName = f\"{scenarioNameBase} / (ID:{scenarioID}) R{periodGroup}/m{userMin_periods_in_PG}/M{userMax_periods_in_PG}\"\n",
    "\n",
    "New_Scenario_Row = {\n",
    "    \"scenarioName\": scenarioName,\n",
    "    \"scenarioRunDate\": int(now.strftime(\"%Y%m%d\")),\n",
    "    \"periodGroup\": periodGroup,\n",
    "    \"runtTimeVersion\": int(runtTimeVersion)\n",
    "}\n",
    "\n",
    "New_Scenario = pl.DataFrame({\n",
    "    \"scenarioID\": [scenarioID],\n",
    "    **{k: [v] for k, v in New_Scenario_Row.items()}\n",
    "})\n",
    "\n",
    "if D0_VersionControl.height == 0:\n",
    "    # If DataFrame was empty (new file), just assign the new DataFrame\n",
    "    D0_VersionControl = New_Scenario\n",
    "else:\n",
    "    # Append new row\n",
    "    D0_VersionControl = D0_VersionControl.vstack(New_Scenario)\n",
    "\n",
    "# Write back to CSV\n",
    "D0_VersionControl.write_csv(input_file, separator=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2efc3f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Data Cleansing\n",
    "D0_Source = D0_Source.with_columns([\n",
    "    pl.when((pl.col(\"costInput\").is_null()) \n",
    "            | (pl.col(\"costInput\") <= 0)\n",
    "            ).then(pl.lit(\"C\")).otherwise(pl.lit(\"\")\n",
    "                                          ).alias(\"flag_costInput\"),\n",
    "    pl.when((pl.col(\"costDriverInput\").is_null()) \n",
    "            | (pl.col(\"costDriverInput\") <= 0)).then(pl.lit(\"V\")).otherwise(pl.lit(\"\")).alias(\"flag_costDriverInput\")\n",
    "])\n",
    "\n",
    "D0_Source = D0_Source.with_columns([\n",
    "    (pl.col(\"flag_costInput\") + pl.col(\"flag_costDriverInput\"))\n",
    "    .alias(\"FlagColumn\")\n",
    "]).with_columns(\n",
    "    pl.when((pl.col(\"FlagColumn\")==pl.lit(\"\"))).then(pl.lit(\"Valid\")).otherwise(pl.col(\"FlagColumn\")).alias(\"FlagColumn\"))\n",
    "\n",
    "D0_Source = D0_Source.drop([ \"flag_costInput\", \"flag_costDriverInput\"])\n",
    "\n",
    "#Output file Disabled, Only to use for internal control\n",
    "#D0_Source.with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).write_csv(\"D0_DataCleansing.csv\",separator=',')\n",
    "\n",
    "D1_DataCleansing=D0_Source.with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).with_columns(pl.lit(scenarioID).alias(\"scenarioID\"))\n",
    "D1_Corporate=D0_Source.filter(pl.col(\"FlagColumn\")==\"Valid\")\n",
    "\n",
    "#Output file Disabled, Only to use for internal control\n",
    "#D0_Source.with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).with_columns(pl.lit(scenarioID).alias(\"scenarioID\")).write_csv(\"D1_Corporate.csv\",separator=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c51db59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Identify unique combinations for obsGroupID\n",
    "D1_Corporate_obsGroupID=D1_Corporate.select(\n",
    "    \"costActivity\",\n",
    "    \"DataGranularityL1\",\n",
    "    \"DataGranularityL2\",\n",
    "    \"DataGranularityL3\",\n",
    "    \"DataGranularityL4\").unique().with_row_index(name=\"obsGroupID\")\n",
    "D1_Corporate=D1_Corporate.join(D1_Corporate_obsGroupID, on=[\n",
    "    \"costActivity\",\n",
    "    \"DataGranularityL1\",\n",
    "    \"DataGranularityL2\",\n",
    "    \"DataGranularityL3\",\n",
    "    \"DataGranularityL4\"],how='inner')\n",
    "\n",
    "#Identify Observations per obsGroupID\n",
    "D1_Corporate_with_ID = (\n",
    "    D1_Corporate\n",
    "      .sort([\"obsGroupID\", \"periodID\"])\n",
    "      .with_columns(\n",
    "          pl.int_range(1, pl.len() + 1)\n",
    "            .over(\"obsGroupID\")\n",
    "            .alias(\"observationID\")\n",
    "      )\n",
    ")\n",
    "#Output file Disabled, Only to use for internal control\n",
    "#D1_Corporate_with_ID.select(    \"observationID\",    \"obsGroupID\",    \"periodID\",    \"costInput\",    \"costDriverInput\",    \"costActivity\",    \"DataGranularityL1\",    \"DataGranularityL2\",    \"DataGranularityL3\",    \"DataGranularityL4\"    ).with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).with_columns(pl.lit(scenarioID).alias(\"scenarioID\")).write_csv(\"D1_Corporate_with_ID.csv\",separator=',')\n",
    "\n",
    "D2_modelInput=D1_Corporate_with_ID.select(\n",
    "    \"observationID\",\n",
    "    \"obsGroupID\",\n",
    "    \"costInput\",\n",
    "    \"costDriverInput\"    \n",
    "    )\n",
    "#Output file Disabled, Only to use for internal control\n",
    "#D2_modelInput.with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).with_columns(pl.lit(scenarioID).alias(\"scenarioID\")).write_csv(\"D2_modelInput.csv\",separator=',')\n",
    "\n",
    "\n",
    "#0.0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ec13d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### RollingPG Generation\n",
    "def RollingPG(numberOfPeriods):\n",
    "    groups = []\n",
    "    num_groups = len(PeriodList) - numberOfPeriods + 1\n",
    "    PeriodList_pd=PeriodList.to_pandas()\n",
    "    for i in range(num_groups):\n",
    "        group = PeriodList_pd.iloc[i:i + numberOfPeriods].copy()  # Copy to avoid SettingWithCopyWarning\n",
    "        \n",
    "        group['PGID'] = i + 1  # Add the PGID column with the current group number\n",
    "        groups.append(group)\n",
    "    # Concatenate all groups into a single DataFrame\n",
    "    \n",
    "    combined_df = pd.concat(groups).reset_index(drop=True)\n",
    "    \n",
    "    # Create a rank column within each PGID\n",
    "    combined_df['SubPeriodID'] = combined_df.groupby('PGID').cumcount() + 1\n",
    "    combined_df['SubPeriodID'] = combined_df['SubPeriodID'].astype(int)\n",
    "    combined_df_pl=pl.from_pandas(combined_df)\n",
    "    combined_df_pl=combined_df_pl.with_columns(pl.col('SubPeriodID').cast(pl.Int64).alias('SubPeriodID'))\n",
    "    combined_df_pl=combined_df_pl.unique(maintain_order=False)    \n",
    "    return combined_df_pl\n",
    "\n",
    "PeriodList=D2_modelInput.select(\"observationID\").unique().sort([\"observationID\"])\n",
    "userNumberOfPeriods=periodGroup\n",
    "periodGroups=RollingPG(userNumberOfPeriods).sort([\"observationID\",\"PGID\",\"SubPeriodID\"])\n",
    "\n",
    "#Output file Disabled, Only to use for internal control\n",
    "#periodGroups.with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).with_columns(pl.lit(scenarioID).alias(\"scenarioID\")).write_csv(\"D2_periodGroups.csv\",separator=',')\n",
    "\n",
    "D3_modelInput=D2_modelInput.join(periodGroups,on=\"observationID\",how=\"inner\")\n",
    "\n",
    "#Output file Disabled, Only to use for internal control\n",
    "#D3_modelInput.with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).with_columns(pl.lit(scenarioID).alias(\"scenarioID\")).write_csv(\"D3_modelInput.csv\",separator=',')\n",
    "\n",
    "#0.0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f6854efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### createBool Mapping\n",
    "def createBool(numberOfPeriods,min_periods_in_PG,max_periods_in_PG):\n",
    "    \n",
    "    column_names = [str(i) for i in range(1, numberOfPeriods + 1)]\n",
    "    num_rows = 2 ** numberOfPeriods\n",
    "    \n",
    "    boolTable = pd.DataFrame(np.nan, index=range(num_rows), columns=column_names)\n",
    "    boolTable['RegressionPGID'] = range(1, num_rows+1) \n",
    "    boolTable['Binary'] = boolTable['RegressionPGID'].apply(lambda x: format(x-1, f'0{numberOfPeriods}b'))\n",
    "    for i in range(numberOfPeriods):\n",
    "        boolTable[column_names[i]] = boolTable['Binary'].apply(lambda x: int(x[i]))\n",
    "    \n",
    "    boolTable['SumOfBits'] = boolTable['Binary'].apply(lambda x: sum(int(bit) for bit in x))\n",
    "    \n",
    "    combined_df = pd.DataFrame()\n",
    "    num_groups = len(PeriodList) - numberOfPeriods + 1\n",
    "    for i in range(1, num_groups + 1):\n",
    "        temp_df = boolTable.copy()\n",
    "        temp_df['PGID'] = i\n",
    "        combined_df = pd.concat([combined_df, temp_df], ignore_index=True)\n",
    "            \n",
    "    # Transpose the values of the columns 1, 2, 3, ..., numberOfPeriods for each PGID\n",
    "    melted_df = combined_df.melt(id_vars=['PGID', 'RegressionPGID', 'Binary', 'SumOfBits'], \n",
    "                                 value_vars=column_names, \n",
    "                                 var_name='SubPeriodID', \n",
    "                                 value_name='Value')\n",
    "    \n",
    "    melted_df['SubPeriodID'] = melted_df['SubPeriodID'].astype(int)\n",
    "    filtered_boolTable = melted_df[(melted_df['SumOfBits'] >= min_periods_in_PG)  & (melted_df['Value'] == 1) &(melted_df['SumOfBits'] <= max_periods_in_PG) ]\n",
    "    \n",
    "    output_df=pl.from_pandas(filtered_boolTable)\n",
    "    \n",
    "    output_df=output_df.unique(maintain_order=False) \n",
    "    output_df=output_df.with_columns(pl.col('SubPeriodID').cast(pl.Int64).alias('SubPeriodID'))\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4c1c5353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Execute createBool Mapping\n",
    "boolTableMask=createBool(userNumberOfPeriods,userMin_periods_in_PG,userMax_periods_in_PG).select(\n",
    "    \"PGID\",\"RegressionPGID\",\"Binary\",\"SumOfBits\",\"SubPeriodID\").sort(\"PGID\",\"RegressionPGID\")\n",
    "\n",
    "\n",
    "#Output file Disabled, Only to use for internal control\n",
    "#boolTableMask.with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).write_csv(\"D4_boolTableMask.csv\",separator=',')\n",
    "\n",
    "D3_modelInput=D3_modelInput.join(boolTableMask, on=[\"PGID\",\"SubPeriodID\"],how=\"inner\").select(\n",
    "    \"observationID\",\"obsGroupID\",\"costInput\",\"costDriverInput\",\"PGID\",\"SubPeriodID\",\"RegressionPGID\").sort([\"PGID\",\"SubPeriodID\",\"RegressionPGID\"])\n",
    "D4_modelInput=D3_modelInput.with_columns((pl.col('obsGroupID').cast(pl.Utf8)+\"_\"+ pl.col('PGID').cast(pl.Utf8)+\"_\"+ pl.col('RegressionPGID').cast(pl.Utf8)).alias('RegressionID')).rename({\"costDriverInput\":\"CostDriver\",\"costInput\":\"Cost\"})\n",
    "\n",
    "#Output file Disabled, Only to use for internal control\n",
    "#D4_modelInput.with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).with_columns(pl.lit(scenarioID).alias(\"scenarioID\")).write_csv(\"D4_modelInput.csv\",separator=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1094c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Vectorized function to solve regressions\n",
    "def manual_regression_worker(SelectedRegression):\n",
    "    X = SelectedRegression['X'].values\n",
    "    Y = SelectedRegression['Y'].values\n",
    "    n = len(X)\n",
    "    X_mean = np.mean(X)\n",
    "    Y_mean = np.mean(Y)\n",
    "    \n",
    "    numerator = np.sum((X - X_mean) * (Y - Y_mean))\n",
    "    denominator = np.sum((X - X_mean) ** 2)\n",
    "    \n",
    "    if denominator == 0:\n",
    "        VarUnitCost = np.nan   \n",
    "        FixCost = np.nan   \n",
    "    else:\n",
    "        VarUnitCost = numerator / denominator\n",
    "        FixCost = Y_mean - VarUnitCost * X_mean\n",
    "    \n",
    "    return [SelectedRegression.name, FixCost]  # VarUnitCost as Slope, not currently in use\n",
    "\n",
    "\n",
    "def produceSolution(Input_df):\n",
    "    Input_df_pd=Input_df.to_pandas()\n",
    "    Input_df_grp = Input_df_pd.groupby(\"RegressionID\")\n",
    "    solution = Input_df_grp.apply(manual_regression_worker).tolist()\n",
    "    solution_df = pd.DataFrame(solution, columns=['RegressionID', 'FixCost']) # VarUnitCost as Slope, not currently in use\n",
    "    solution_df_pl=pl.from_pandas(solution_df)\n",
    "    return solution_df_pl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "19e4beb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_7896\\3441907669.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  solution = Input_df_grp.apply(manual_regression_worker).tolist()\n"
     ]
    }
   ],
   "source": [
    "#################################### Model Execution\n",
    "max_cost_df = D4_modelInput.group_by('obsGroupID','PGID').agg(pl.col('Cost').min())\n",
    "max_cost_df = max_cost_df.rename({'Cost': 'PGminCost'})\n",
    "RegressionInput=D4_modelInput.select('RegressionID','CostDriver','Cost').rename({'CostDriver':'X','Cost':'Y'})\n",
    "D5_modelOutput=produceSolution(RegressionInput).select(\"RegressionID\",\"FixCost\").join(D4_modelInput, on=\"RegressionID\", how=\"inner\" ).join(max_cost_df,on=(\"PGID\",\"obsGroupID\"),how=\"inner\")\n",
    "\n",
    "#Output file Disabled, Only to use for internal control\n",
    "#D5_modelOutput.with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).with_columns(pl.lit(scenarioID).alias(\"scenarioID\")).write_csv(\"D5_modelOutput.csv\",separator=',')\n",
    "\n",
    "#3.6s RP6\n",
    "#s2m54s RP9  40.13M Regressions min model Acc 7.34 % AVG 89.56%\n",
    "#>27m  RP12  544.78M Regressions min 14.74 AVG 89.26%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "30c1c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Business Rules\n",
    "#Business Rule 1\n",
    "D6_modelOutput_BusinessRules=D5_modelOutput.filter(\n",
    "    pl.col('FixCost')>=0) \n",
    "#Business Rule 2\n",
    "D6_modelOutput_BusinessRules=D6_modelOutput_BusinessRules.filter(\n",
    "    pl.col('FixCost')<pl.col('PGminCost')) \n",
    "\n",
    "#Output file Disabled, Only to use for internal control\n",
    "#D6_modelOutput_BusinessRules.with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).with_columns(pl.lit(scenarioID).alias(\"scenarioID\")).write_csv(\"D6_modelOutput_BusinessRules.csv\",separator=',')\n",
    "\n",
    "\n",
    "#0.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8e8a47dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### DEF Median Calculation\n",
    "def calculate_median(D6_modelOutput):\n",
    "    D6_modelOutput=D6_modelOutput.with_columns((pl.col('obsGroupID').cast(pl.Utf8)+\"_\"+ pl.col('PGID').cast(pl.Utf8)).alias('obsGroupIDPG_ID'))\n",
    "    Solution_Median_step1 = D6_modelOutput.select(pl.col('obsGroupIDPG_ID','FixCost').sort_by('obsGroupIDPG_ID','FixCost'))\n",
    "    Solution_Median_step2=Solution_Median_step1.group_by('obsGroupIDPG_ID', maintain_order=True).median()\n",
    "        \n",
    "    \n",
    "    IQR=D6_modelOutput.group_by(\"obsGroupIDPG_ID\").agg([\n",
    "        pl.col(\"FixCost\").quantile(0.25).alias(\"Q1\"),\n",
    "        pl.col(\"FixCost\").quantile(0.75).alias(\"Q3\"),\n",
    "        pl.col(\"FixCost\").median().alias(\"Median\")\n",
    "    ]).with_columns(\n",
    "        ((pl.col(\"Q3\") - pl.col(\"Q1\")) / pl.col(\"Median\")).alias(\"IQR\")\n",
    "    ).select([\"obsGroupIDPG_ID\", \"IQR\"])  \n",
    "        \n",
    "        \n",
    "        \n",
    "    Solution_Median_step2=Solution_Median_step2.rename({'FixCost':'FixCost_Solution'})\n",
    "    Solution_Median_step3=Solution_Median_step1.group_by('obsGroupIDPG_ID').min()\n",
    "    Solution_Median_step3=Solution_Median_step3.rename({'FixCost':'MinFixCost'})\n",
    "    Solution_Median_step4=Solution_Median_step1.group_by('obsGroupIDPG_ID').max()\n",
    "    Solution_Median_step4=Solution_Median_step4.rename({'FixCost':'MaxFixCost'})\n",
    "    \n",
    "    Solution_Median_step1a=Solution_Median_step1.join(Solution_Median_step2,left_on=['obsGroupIDPG_ID'], right_on=['obsGroupIDPG_ID'], how='inner')\n",
    "    Solution_Median_step2a=Solution_Median_step1a.join(Solution_Median_step3,left_on=['obsGroupIDPG_ID'], right_on=['obsGroupIDPG_ID'], how='inner')\n",
    "    Solution_Median_step3a=Solution_Median_step2a.join(Solution_Median_step4,left_on=['obsGroupIDPG_ID'], right_on=['obsGroupIDPG_ID'], how='inner')\n",
    "    \n",
    "    Solution_Median_step3a=Solution_Median_step3a.with_columns((pl.col('MinFixCost')-pl.col('FixCost_Solution')).alias('MinFixCost'))\n",
    "    Solution_Median_step3a=Solution_Median_step3a.with_columns((pl.col('MaxFixCost')-pl.col('FixCost_Solution')).alias('MaxFixCost'))\n",
    "    Solution_Median_step3a=Solution_Median_step3a.with_columns((pl.col('FixCost')-pl.col('FixCost_Solution')).alias('FixCost'))\n",
    "    \n",
    "    \n",
    "    Solution_Median_step3a=Solution_Median_step3a.with_columns((-pl.col('FixCost')/pl.col('MinFixCost')).round(3).alias('MinFixCost'))\n",
    "    Solution_Median_step3a=Solution_Median_step3a.with_columns((pl.col('FixCost')/pl.col('MaxFixCost')).round(3).alias('MaxFixCost'))\n",
    "    \n",
    "    Solution_Median_step3a=Solution_Median_step3a.with_columns(pl.col('MinFixCost').fill_nan(0))\n",
    "    Solution_Median_step3a=Solution_Median_step3a.with_columns(pl.col('MaxFixCost').fill_nan(0))\n",
    "    Solution_Median_step3a=Solution_Median_step3a.with_columns(pl.when(pl.col('FixCost') >= 0).then(pl.col('MaxFixCost')).otherwise(pl.col('MinFixCost')).alias('DispersionREF'))\n",
    "        \n",
    "\n",
    "    \n",
    "    Solution_Median_step3a=Solution_Median_step3a.with_columns(\n",
    "        pl.when((pl.col('DispersionREF') >= 0)&(pl.col('DispersionREF') <= 0.1)).then(pl.lit('P0')).\n",
    "        when((pl.col('DispersionREF') > 0.1)&(pl.col('DispersionREF') <= 0.2)).then(pl.lit('P10')).\n",
    "        when((pl.col('DispersionREF') > 0.2)&(pl.col('DispersionREF') <= 0.3)).then(pl.lit('P20')).\n",
    "        when((pl.col('DispersionREF') > 0.3)&(pl.col('DispersionREF') <= 0.4)).then(pl.lit('P30')).\n",
    "        when((pl.col('DispersionREF') > 0.4)&(pl.col('DispersionREF') <= 0.5)).then(pl.lit('P40')).\n",
    "        when((pl.col('DispersionREF') > 0.5)&(pl.col('DispersionREF') <= 0.6)).then(pl.lit('P50')).\n",
    "        when((pl.col('DispersionREF') > 0.6)&(pl.col('DispersionREF') <= 0.7)).then(pl.lit('P60')).\n",
    "        when((pl.col('DispersionREF') > 0.7)&(pl.col('DispersionREF') <= 0.8)).then(pl.lit('P70')).\n",
    "        when((pl.col('DispersionREF') > 0.8)&(pl.col('DispersionREF') <= 0.9)).then(pl.lit('P80')).\n",
    "        when((pl.col('DispersionREF') > 0.9)).then(pl.lit('P90')).\n",
    "        when((pl.col('DispersionREF') < 0)&(pl.col('DispersionREF') >= -0.1)).then(pl.lit('N0')).\n",
    "        when((pl.col('DispersionREF') < -0.1)&(pl.col('DispersionREF') >= -0.2)).then(pl.lit('N10')).\n",
    "        when((pl.col('DispersionREF') < -0.2)&(pl.col('DispersionREF') >= -0.3)).then(pl.lit('N20')).\n",
    "        when((pl.col('DispersionREF') < -0.3)&(pl.col('DispersionREF') >= -0.4)).then(pl.lit('N30')).\n",
    "        when((pl.col('DispersionREF') < -0.4)&(pl.col('DispersionREF') >= -0.5)).then(pl.lit('N40')).\n",
    "        when((pl.col('DispersionREF') < -0.5)&(pl.col('DispersionREF') >= -0.6)).then(pl.lit('N50')).\n",
    "        when((pl.col('DispersionREF') < -0.6)&(pl.col('DispersionREF') >= -0.7)).then(pl.lit('N60')).\n",
    "        when((pl.col('DispersionREF') < -0.7)&(pl.col('DispersionREF') >= -0.8)).then(pl.lit('N70')).\n",
    "        when((pl.col('DispersionREF') < -0.8)&(pl.col('DispersionREF') >= -0.9)).then(pl.lit('N80')).\n",
    "        when((pl.col('DispersionREF') < -0.9)).then(pl.lit('N90')).\n",
    "        otherwise(pl.lit('-666')).alias('DispersionCAT')\n",
    "        )\n",
    "    \n",
    "    Solution_Median_W_Dis=Solution_Median_step3a.group_by('obsGroupIDPG_ID','DispersionCAT','FixCost_Solution').agg( pl.len().alias('NumberOfSolutions'))\n",
    "    \n",
    "    Solution_Median_W_Dis_pv=Solution_Median_W_Dis.pivot(values='NumberOfSolutions',index=['obsGroupIDPG_ID','FixCost_Solution'],on='DispersionCAT')\n",
    "    Solution_Median_W_Dis_pv=Solution_Median_W_Dis_pv.fill_null(0)\n",
    "    columns_to_check = ['-666','N0', 'N10', 'N20', 'N30', 'N40', 'N50', 'N60', 'N70', 'N80', 'N90','P0',\n",
    "                    'P10', 'P20', 'P30', 'P40', 'P50', 'P60', 'P70', 'P80', 'P90']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for col in columns_to_check:\n",
    "        if col not in Solution_Median_W_Dis_pv.columns:\n",
    "            Solution_Median_W_Dis_pv = Solution_Median_W_Dis_pv.with_columns(pl.lit(0).alias(col))\n",
    "    \n",
    "    \n",
    "    review_solutions_step2=D6_modelOutput.select('observationID','obsGroupID','PGID','CostDriver','Cost','obsGroupIDPG_ID').unique()\n",
    "    \n",
    "    review_solutions_step9=review_solutions_step2.join(Solution_Median_W_Dis_pv, left_on=['obsGroupIDPG_ID'],right_on=['obsGroupIDPG_ID'], how='inner')\n",
    "    review_solutions_step9=review_solutions_step9.join(IQR, left_on=['obsGroupIDPG_ID'],right_on=['obsGroupIDPG_ID'], how='inner')\n",
    "    \n",
    "    review_solutions_step9a=review_solutions_step9.select('observationID','obsGroupID','CostDriver','Cost','FixCost_Solution','P90',\t'N90',\t'N50',\t'P10',\t'N40',\t'P60',\t'P50',\t'N20',\t'P80',\t'P70',\t'N30',\t'N70',\t'N10',\t'N60',\t'P0',\t'N0',\t'P20',\t'P30',\t'N80',\t'P40',\t'-666',\"IQR\")\n",
    "    review_solutions_step10=review_solutions_step9a.group_by('observationID','obsGroupID','CostDriver','Cost').agg([\n",
    "        pl.col('FixCost_Solution').mean(),\n",
    "        pl.col('IQR').mean().alias(\"AVG_IQR\"),\n",
    "        pl.col('P90','N90',\t'N50',\t'P10',\t'N40',\t'P60',\t'P50',\t'N20',\t'P80',\t'P70',\t'N30',\t'N70',\t'N10',\t'N60',\t'P0',\t'N0',\t'P20',\t'P30',\t'N80',\t'P40',\t'-666').sum()\n",
    "        ])\n",
    "    \n",
    "    \n",
    "    Final_AVG=review_solutions_step10.with_columns((pl.col('Cost')-pl.col('FixCost_Solution')).alias('varCost'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    Final_AVG=Final_AVG.select('observationID','obsGroupID','CostDriver','Cost','FixCost_Solution','varCost','N90','N80','N70','N60','N50','N40','N30','N20','N10','N0','P0','P10','P20','P30','P40','P50','P60','P70','P80','P90','-666',\"AVG_IQR\")\n",
    "    return Final_AVG.with_columns(\n",
    "    pl.sum_horizontal(pl.col([\n",
    "        'N90','N80','N70','N60','N50','N40','N30','N20','N10','N0',\n",
    "        'P0','P10','P20','P30','P40','P50','P60','P70','P80','P90','-666'\n",
    "    ])).alias('TotalRegressions')\n",
    ")\n",
    "    \n",
    "\n",
    "#0.0 6RP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6f951c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Median Calculation\n",
    "D7_Avg_Median=calculate_median(D6_modelOutput_BusinessRules)\n",
    "\n",
    "\n",
    "\n",
    "#output_folder = f\"\"\n",
    "#output_file = os.path.join(output_folder, f'D7_Avg_Median.csv')\n",
    "#Output file Disabled, Only to use for internal control\n",
    "#D7_Avg_Median.with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).with_columns(pl.lit(scenarioID).alias(\"scenarioID\")).write_csv(output_file,separator=',')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b903e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### FILLING GAPS\n",
    "pre_modelOutput=D1_Corporate_with_ID.select(\"observationID\",\"obsGroupID\",\"costInput\",\"costDriverInput\").join(\n",
    "    D7_Avg_Median.rename({\n",
    "    \"Cost\":\"costModel\",\n",
    "    \"CostDriver\":\"costDriverModel\",\n",
    "    \"FixCost_Solution\":\"fixCostModel\",\n",
    "})\n",
    "    ,\n",
    "        on=[\"observationID\",\"obsGroupID\"],\n",
    "        how=\"left\" ).with_columns(\n",
    "    pl.when(\n",
    "        (pl.col(\"fixCostModel\") <= 0) | (pl.col(\"fixCostModel\").is_null())\n",
    "    )\n",
    "    .then(pl.lit(-1))\n",
    "    .otherwise(pl.lit(0))\n",
    "    .alias(\"isValid\"))\n",
    "\n",
    "modelOutput_with_nulls=pre_modelOutput.select(\"obsGroupID\",\"observationID\",\"fixCostModel\").sort(\"obsGroupID\",\"observationID\").pivot(values=\"fixCostModel\",index=\"obsGroupID\",on=\"observationID\")\n",
    "\n",
    "cols = [str(i) for i in range(1, modelOutput_with_nulls.width)]  \n",
    "\n",
    "\n",
    "data = modelOutput_with_nulls.select(cols).to_numpy()\n",
    "\n",
    "\n",
    "for r in range(data.shape[0]):\n",
    "    row = data[r]\n",
    "    not_null_indices = np.where(~np.isnan(row))[0]\n",
    "\n",
    "    for i in range(len(not_null_indices) - 1):\n",
    "        left_idx = not_null_indices[i]\n",
    "        right_idx = not_null_indices[i + 1]\n",
    "\n",
    "        gap = right_idx - left_idx\n",
    "        if gap > 1:\n",
    "            left_val = row[left_idx]\n",
    "            right_val = row[right_idx]\n",
    "\n",
    "            for j in range(1, gap):\n",
    "                interp_val = left_val + (right_val - left_val) * j / gap\n",
    "                row[left_idx + j] = interp_val\n",
    "\n",
    "    data[r] = row\n",
    "\n",
    "\n",
    "def ffill_row(row):\n",
    "    for i in range(1, len(row)):\n",
    "        if np.isnan(row[i]):\n",
    "            row[i] = row[i-1]\n",
    "    return row\n",
    "\n",
    "\n",
    "def bfill_row(row):\n",
    "    for i in range(len(row)-2, -1, -1):\n",
    "        if np.isnan(row[i]):\n",
    "            row[i] = row[i+1]\n",
    "    return row\n",
    "\n",
    "\n",
    "for r in range(data.shape[0]):\n",
    "    data[r] = ffill_row(data[r])\n",
    "\n",
    "\n",
    "for r in range(data.shape[0]):\n",
    "    data[r] = bfill_row(data[r])\n",
    "\n",
    "\n",
    "data_dict = {col: data[:, i] for i, col in enumerate(cols)}\n",
    "\n",
    "\n",
    "df_filled = pl.DataFrame(data_dict)\n",
    "\n",
    "\n",
    "modelOutput_filled = modelOutput_with_nulls.select(\"obsGroupID\").with_columns(df_filled)\n",
    "\n",
    "cols_except_obsGroupID = [col for col in modelOutput_filled.columns if col != \"obsGroupID\"]\n",
    "\n",
    "modelOutput_filled=modelOutput_filled.unpivot(\n",
    "    index=[\"obsGroupID\"],\n",
    "    on=cols_except_obsGroupID,\n",
    "    variable_name=\"observationID\",\n",
    "    value_name=\"fixCostModel_FF\"\n",
    ").with_columns(\n",
    "    pl.col(\"observationID\").cast(pl.Int64)\n",
    ")\n",
    "\n",
    "\n",
    "modelOutput=pre_modelOutput.join(modelOutput_filled,on=[\"observationID\",\"obsGroupID\"],\n",
    "        how=\"left\" ).with_columns(pl.when(\n",
    "                pl.col(\"fixCostModel\").is_null()).then(pl.col(\"fixCostModel_FF\")).otherwise(pl.col(\"fixCostModel\")).alias(\"fixCostModel\")).drop(\"fixCostModel_FF\")\n",
    "\n",
    "\n",
    "#modelOutput=modelOutput.with_columns(pl.when(pl.col(\"costInput\")<=pl.col(\"fixCostModel\")).then(pl.col(\"costInput\")).otherwise(pl.col(\"fixCostModel\")).alias(\"fixCost\"))\n",
    "modelOutput=modelOutput.with_columns(pl.col(\"fixCostModel\").alias(\"fixCost\"))\n",
    "\n",
    "modelOutput=modelOutput.with_columns(\n",
    "                                       (pl.col(\"costInput\")-pl.col(\"fixCost\")\n",
    "                                        ).alias(\"varCost\"))\n",
    "\n",
    "modelOutput=modelOutput.with_columns(\n",
    "    pl.arange(1, modelOutput.height + 1).alias('solutionID')\n",
    ")\n",
    "\n",
    "D7_Avg_Median=modelOutput.rename({\"costModel\":\"Cost\",\n",
    "    \"costDriverModel\":\"CostDriver\",\n",
    "    \"fixCostModel\":\"FixCost_Solution\"}).select(\n",
    "    'observationID',\t'obsGroupID',\t'CostDriver',\t'Cost',\t'FixCost_Solution',\t'varCost',\t'N90',\t'N80',\t'N70',\t'N60',\t'N50',\t'N40',\t'N30',\t'N20',\t'N10',\t'N0',\t'P0',\t'P10',\t'P20',\t'P30',\t'P40',\t'P50',\t'P60',\t'P70',\t'P80',\t'P90',\t'-666',\t'AVG_IQR',\t'TotalRegressions','solutionID'\n",
    "    )\n",
    "\n",
    "modelOutput=modelOutput.with_columns(pl.lit(scenarioID).alias(\"scenarioID\")).select(\"observationID\",\"scenarioID\",\"solutionID\",\"isValid\",\"costInput\",\"costDriverInput\",\"costModel\",\"costDriverModel\",\"fixCostModel\",\"fixCost\",\"varCost\",\"obsGroupID\").with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c24c9347",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################   END OF MODELING ##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0c4b343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Preparation for Power BI Data ingestion\n",
    "dataGranularity=D1_Corporate_with_ID.with_columns(pl.lit(\"Y\").alias(\"isGranular\")).with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).rename(    \n",
    "    {\"DataGranularityL1\":\"dataGranularityL1\",\n",
    "     \"DataGranularityL2\":\"dataGranularityL2\",\n",
    "     \"DataGranularityL3\":\"dataGranularityL3\",\n",
    "     \"DataGranularityL4\":\"dataGranularityL4\"}).select(\"isGranular\",\"dataGranularityL1\",\"dataGranularityL2\",\"dataGranularityL3\",\"dataGranularityL4\",\"runtTimeVersion\",\"observationID\",\"obsGroupID\")\n",
    "\n",
    "modelInput=D1_Corporate_with_ID.with_columns(pl.lit(\"Y\").alias(\"isGranular\")).with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).rename(    \n",
    "    {\"DataGranularityL1\":\"dataGranularityL1\",\n",
    "     \"DataGranularityL2\":\"dataGranularityL2\",\n",
    "     \"DataGranularityL3\":\"dataGranularityL3\",\n",
    "     \"DataGranularityL4\":\"dataGranularityL4\"}).select(\n",
    "         \"observationID\",\"obsGroupID\",\"periodID\",\"costInput\",\"costDriverInput\",\"costActivity\",\n",
    "                                                      \"dataGranularityL1\",\"dataGranularityL2\",\"dataGranularityL3\",\"dataGranularityL4\",\"isGranular\",\"runtTimeVersion\")\n",
    "modelscenario=D0_VersionControl.with_columns(\n",
    "    pl.lit(userMin_periods_in_PG).alias(\"Min_Periods\"),\n",
    "    pl.lit(userMax_periods_in_PG).alias(\"Max_Periods\")\n",
    "    )\n",
    "modelAccuracyOutput=D7_Avg_Median.select(\"obsGroupID\",'N90','N80','N70','N60','N50','N40','N30','N20','N10','N0','P0','P10','P20','P30','P40','P50','P60','P70','P80','P90','-666',\"solutionID\",\"AVG_IQR\").with_columns(pl.lit(runtTimeVersion).alias(\"runtTimeVersion\")).with_columns(pl.lit(scenarioID).alias(\"scenarioID\"))\n",
    "modelAccuracyOutput=modelAccuracyOutput.unpivot(\n",
    "    index=[\"obsGroupID\",\"solutionID\", \"runtTimeVersion\", \"scenarioID\",\"AVG_IQR\"],\n",
    "    on=[\n",
    "        'N90','N80','N70','N60','N50','N40','N30','N20','N10','N0',\n",
    "        'P0','P10','P20','P30','P40','P50','P60','P70','P80','P90',\n",
    "        '-666'\n",
    "    ],\n",
    "    variable_name=\"dispersionCat\",\n",
    "    value_name=\"Value\"\n",
    ")\n",
    "\n",
    "modelAccuracyOutput=modelAccuracyOutput.with_columns(pl.col(\"dispersionCat\").str.replace(\"N0\", \"P0\").alias(\"dispersionCat\"))\n",
    "modelAccuracyOutput=modelAccuracyOutput.with_columns(\n",
    "    pl.when(pl.col(\"dispersionCat\")==\"P0\").then(pl.lit(\"Med\"))\n",
    "    .when(pl.col(\"dispersionCat\").str.starts_with(\"N\")).then(pl.lit(\"-\"))\n",
    "    .when(pl.col(\"dispersionCat\").str.starts_with(\"P\")).then(pl.lit(\"+\"))\n",
    "    .otherwise(pl.lit(\"\"))\n",
    "    .alias(\"dispersionSig\")\n",
    ")\n",
    "\n",
    "modelAccuracyOutput=modelAccuracyOutput.with_columns(pl.col(\"dispersionCat\").str.replace(\"N\", \"-\").alias(\"dispersionCat\"))\n",
    "modelAccuracyOutput=modelAccuracyOutput.with_columns(pl.col(\"dispersionCat\").str.replace(\"P\", \"\").alias(\"dispersionCat\"))\n",
    "\n",
    "modelAccuracyOutput=modelAccuracyOutput.with_columns(\n",
    "pl.when(pl.col(\"dispersionSig\")==\"-\").then(pl.lit(\"3\"))\n",
    "    .when(pl.col(\"dispersionSig\")==\"+\").then(pl.lit(\"1\"))\n",
    "    .otherwise(pl.lit(\"2\")).alias(\"dispersionSigOrder\")\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cols_to_keep = [\"obsGroupID\", \"fixCost\",\"runtTimeVersion\",\"scenarioID\"]\n",
    "\n",
    "Intercept_modelOutput = modelOutput.with_columns([\n",
    "    pl.col(col).alias(col) if col in cols_to_keep else pl.lit(0).alias(col)\n",
    "    for col in modelOutput.columns\n",
    "])\n",
    "\n",
    "group_cols = [col for col in Intercept_modelOutput.columns if col != \"fixCost\"]\n",
    "\n",
    "Intercept_modelOutput = Intercept_modelOutput.group_by(group_cols).agg(\n",
    "    pl.col(\"fixCost\").mean().alias(\"fixCost\")\n",
    ")\n",
    "\n",
    "schema_modelOutput = modelOutput.schema\n",
    "\n",
    "for col, dtype in schema_modelOutput.items():\n",
    "    if col in Intercept_modelOutput.columns:\n",
    "        Intercept_modelOutput = Intercept_modelOutput.with_columns(pl.col(col).cast(dtype))\n",
    "\n",
    "Intercept_modelOutput = Intercept_modelOutput.with_columns(\n",
    "    pl.when(pl.col(\"observationID\") == 0)\n",
    "      .then(pl.col(\"fixCost\"))\n",
    "      .otherwise(pl.col(\"costInput\"))\n",
    "      .alias(\"costInput\")\n",
    ")\n",
    "\n",
    "Intercept_modelOutput=Intercept_modelOutput.select(\n",
    "    'observationID','scenarioID','solutionID','isValid','costInput','costDriverInput','costModel',\n",
    "'costDriverModel','fixCostModel','fixCost','varCost','obsGroupID','runtTimeVersion')\n",
    "\n",
    "modelOutput_W_intercept = pl.concat([modelOutput, Intercept_modelOutput])\n",
    "\n",
    "cols_to_keep = [\"obsGroupID\", \"costInput\",\"runtTimeVersion\"\n",
    "                \n",
    "                ,\"costActivity\",\"dataGranularityL1\",\"dataGranularityL2\",\"dataGranularityL3\",\"dataGranularityL4\",\"isGranular\"\n",
    "                \n",
    "                ]\n",
    "\n",
    "Intercept_modelInput = modelInput.with_columns([\n",
    "    pl.col(col).alias(col) if col in cols_to_keep else pl.lit(0).alias(col)\n",
    "    for col in modelInput.columns\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "group_cols = [col for col in Intercept_modelInput.columns if col != \"costInput\"]\n",
    "\n",
    "Intercept_modelInput = Intercept_modelInput.group_by(group_cols).agg(\n",
    "    pl.col(\"costInput\").mean().alias(\"costInput\")\n",
    ")\n",
    "\n",
    "schema_modelInput = modelInput.schema\n",
    "\n",
    "for col, dtype in schema_modelInput.items():\n",
    "    if col in Intercept_modelInput.columns:\n",
    "        Intercept_modelInput = Intercept_modelInput.with_columns(pl.col(col).cast(dtype))\n",
    "\n",
    "Intercept_modelInput=Intercept_modelInput.select(\n",
    "'observationID',\n",
    "'obsGroupID',\n",
    "'periodID',\n",
    "'costInput',\n",
    "'costDriverInput',\n",
    "'costActivity',\n",
    "'dataGranularityL1',\n",
    "'dataGranularityL2',\n",
    "'dataGranularityL3',\n",
    "'dataGranularityL4',\n",
    "'isGranular',\n",
    "'runtTimeVersion'\n",
    ")\n",
    "\n",
    "modelInput_W_intercept = pl.concat([modelInput, Intercept_modelInput])\n",
    "\n",
    "schema_modelInput = dataGranularity.schema\n",
    "Intercept_dataGranularity=dataGranularity.with_columns(pl.lit(0).alias(\"observationID\")).select(\n",
    "    'isGranular',\t'dataGranularityL1',\t'dataGranularityL2',\t'dataGranularityL3',\t'dataGranularityL4',\t'runtTimeVersion',\t'observationID',\t'obsGroupID'\n",
    ").unique()\n",
    "for col, dtype in schema_modelInput.items():\n",
    "    if col in Intercept_dataGranularity.columns:\n",
    "        Intercept_dataGranularity = Intercept_dataGranularity.with_columns(pl.col(col).cast(dtype))\n",
    "dataGranularity_W_intercept=pl.concat([dataGranularity,Intercept_dataGranularity])\n",
    "\n",
    "schema_modelInput = modelAccuracyOutput.schema\n",
    "\n",
    "Intercept_modelAccuracyOutput=modelAccuracyOutput.with_columns(\n",
    "    pl.lit(\"0\").alias(\"solutionID\"),\n",
    "    pl.lit(\"-666\").alias(\"dispersionCat\"),\n",
    "    pl.lit(0).alias(\"AVG_IQR\"),\n",
    "    pl.lit(\"\").alias(\"dispersionSig\"),\n",
    "    pl.lit(\"2\").alias(\"dispersionSigOrder\"),\n",
    "    pl.lit(0).alias(\"Value\"),\n",
    "    ).unique().select(\"obsGroupID\",'solutionID',\t'runtTimeVersion',\t'scenarioID',\t\"AVG_IQR\",'dispersionCat',\t'Value',\t'dispersionSig',\t'dispersionSigOrder')\n",
    "\n",
    "for col, dtype in schema_modelInput.items():\n",
    "    if col in Intercept_modelAccuracyOutput.columns:\n",
    "        Intercept_modelAccuracyOutput = Intercept_modelAccuracyOutput.with_columns(pl.col(col).cast(dtype))\n",
    "\n",
    "modelAccuracyOutput_W_intercept=pl.concat([modelAccuracyOutput,Intercept_modelAccuracyOutput])\n",
    "\n",
    "modelInput_W_intercept=modelInput_W_intercept.with_columns([\n",
    "    pl.col(\"observationID\").cast(pl.Utf8),\n",
    "    pl.col(\"obsGroupID\").cast(pl.Utf8),\n",
    "    pl.concat_str([\"observationID\", \"obsGroupID\",pl.lit(scenarioID)], separator=\"_\").alias(\"PK_ID\")\n",
    "])\n",
    "\n",
    "modelOutput_W_intercept=modelOutput_W_intercept.with_columns([\n",
    "    pl.col(\"observationID\").cast(pl.Utf8),\n",
    "    pl.col(\"obsGroupID\").cast(pl.Utf8),\n",
    "    pl.concat_str([\"observationID\", \"obsGroupID\",'scenarioID'], separator=\"_\").alias(\"PK_ID\")\n",
    "]).with_columns([\n",
    "    pl.col(\"obsGroupID\").cast(pl.Utf8),\n",
    "    pl.col(\"solutionID\").cast(pl.Utf8),\n",
    "    pl.concat_str([\"obsGroupID\", \"solutionID\",'scenarioID'], separator=\"_\").alias(\"PK_IDs\")\n",
    "])\n",
    "\n",
    "dataGranularity_W_intercept=dataGranularity_W_intercept.with_columns([\n",
    "    pl.col(\"observationID\").cast(pl.Utf8),\n",
    "    pl.col(\"obsGroupID\").cast(pl.Utf8),\n",
    "    pl.concat_str([\"observationID\", \"obsGroupID\",pl.lit(scenarioID)], separator=\"_\").alias(\"PK_ID\")\n",
    "])\n",
    "\n",
    "modelAccuracyOutput_W_intercept=modelAccuracyOutput_W_intercept.with_columns([\n",
    "    pl.col(\"obsGroupID\").cast(pl.Utf8),\n",
    "    pl.col(\"solutionID\").cast(pl.Utf8),\n",
    "    pl.concat_str([\"obsGroupID\", \"solutionID\",'scenarioID'], separator=\"_\").alias(\"PK_IDs\")\n",
    "])\n",
    "\n",
    "modelInput_W_intercept=modelInput_W_intercept.with_columns(pl.when(pl.col(\"observationID\")==\"0\").then(pl.lit(\" Modeled Cost\")).otherwise(pl.lit(\"Business Input\")).alias(\"Source\"))\n",
    "modelOutput_W_intercept=modelOutput_W_intercept.with_columns(pl.when(pl.col(\"observationID\")==\"0\").then(pl.lit(\" Modeled Cost\")).otherwise(pl.lit(\"Business Input\")).alias(\"Source\"))\n",
    "dataGranularity_W_intercept=dataGranularity_W_intercept.with_columns(pl.when(pl.col(\"observationID\")==\"0\").then(pl.lit(\" Modeled Cost\")).otherwise(pl.lit(\"Business Input\")).alias(\"Source\"))\n",
    "modelAccuracyOutput_W_intercept=modelAccuracyOutput_W_intercept.with_columns(pl.when(pl.col(\"solutionID\")==\"0\").then(pl.lit(\" Modeled Cost\")).otherwise(pl.lit(\"Business Input\")).alias(\"Source\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edca9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################  APPEND MODEL RESULTS TO POWER BI DATA SOURCES \n",
    "output_folder = f\"../Custom_PowerBIVisual/data/\"\n",
    "\n",
    "\n",
    "def cast_df_to_schema(df: pl.DataFrame, reference_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    ref_schema = reference_df.schema\n",
    "    for col, dtype in ref_schema.items():\n",
    "        if col in df.columns:\n",
    "            df = df.with_columns(df[col].cast(dtype))\n",
    "    return df\n",
    "\n",
    "def append_polars_to_csv(df: pl.DataFrame, filename: str):\n",
    "    output_file = os.path.join(output_folder, filename)\n",
    "    if os.path.exists(output_file):\n",
    "        existing_df = pl.read_csv(output_file)\n",
    "        existing_df = cast_df_to_schema(existing_df, df)\n",
    "        df = cast_df_to_schema(df, df)  # ensure df columns have correct types (optional)\n",
    "        combined_df = pl.concat([existing_df, df])\n",
    "    else:\n",
    "        combined_df = df\n",
    "    combined_df.write_csv(output_file)\n",
    "\n",
    "output_file = os.path.join(output_folder, f'modelscenario.csv')\n",
    "modelscenario.write_csv(output_file,separator=',')\n",
    "\n",
    "append_polars_to_csv(dataGranularity_W_intercept, 'dataGranularity.csv')\n",
    "append_polars_to_csv(modelInput_W_intercept, 'modelInput.csv')\n",
    "append_polars_to_csv(modelAccuracyOutput_W_intercept, 'modelAccuracyOutput.csv')\n",
    "append_polars_to_csv(modelOutput_W_intercept, 'modelOutput.csv')\n",
    "append_polars_to_csv(D1_DataCleansing, 'DataCleansing.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
